{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np # linear algebra\r\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
    "from sklearn.utils.multiclass import unique_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpimg\r\n",
    "import seaborn as sns\r\n",
    "%matplotlib inline\r\n",
    "import itertools\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import keras functions\r\n",
    "\r\n",
    "from keras import Sequential\r\n",
    "\r\n",
    "'''Since we are using transfer learning let's import the model that we want to implement.Let's use VGG 19(19 layers) and Resnet-50 (50 layers of residual units). \r\n",
    "Residual units allow us to add more layers onto the model without a degradation in accuracy.\r\n",
    "Let's try and compare the accuracy of the 2 models and see if the addtional layers do make a significant difference. '''\r\n",
    "\r\n",
    "from keras.applications import VGG19,ResNet50\r\n",
    "\r\n",
    "'Import the datagenerator to augment images'\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "'''Import the optimizers and leanring rate annealer (which will reduce the learning rate once a particular metric we choose(in this case validation error) \r\n",
    "does not reduce after a user defined number of epochs)'''\r\n",
    "from keras.optimizers import SGD,Adam\r\n",
    "from keras.callbacks import ReduceLROnPlateau\r\n",
    "\r\n",
    "'Lastly import the final layers that will be added on top of the base model'\r\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\r\n",
    "\r\n",
    "'Import to_categorical from the keras utils package to one hot encode the labels'\r\n",
    "from keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import dataset\r\n",
    "from keras.datasets import cifar10\r\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\r\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\r\n",
    "\r\n",
    "print((x_train.shape,y_train.shape))\r\n",
    "print((x_val.shape,y_val.shape))\r\n",
    "print((x_test.shape,y_test.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#One hot encode the labels.Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\r\n",
    "\r\n",
    "y_train=to_categorical(y_train)\r\n",
    "y_val=to_categorical(y_val)\r\n",
    "y_test=to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lets print the dimensions one more time to see if things changed the way we expected\r\n",
    "\r\n",
    "print((x_train.shape,y_train.shape))\r\n",
    "print((x_val.shape,y_val.shape))\r\n",
    "print((x_test.shape,y_test.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_generator = ImageDataGenerator(\r\n",
    "                                    rotation_range=2, \r\n",
    "                                    horizontal_flip=True,\r\n",
    "                                    zoom_range=.1 )\r\n",
    "\r\n",
    "val_generator = ImageDataGenerator(\r\n",
    "                                    rotation_range=2, \r\n",
    "                                    horizontal_flip=True,\r\n",
    "                                    zoom_range=.1)\r\n",
    "\r\n",
    "test_generator = ImageDataGenerator(\r\n",
    "                                    rotation_range=2, \r\n",
    "                                    horizontal_flip= True,\r\n",
    "                                    zoom_range=.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Fit the augmentation method to the data\r\n",
    "#wefkhwejkfhwe\r\n",
    "train_generator.fit(x_train)\r\n",
    "val_generator.fit(x_val)\r\n",
    "test_generator.fit(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrr= ReduceLROnPlateau(\r\n",
    "                       monitor='val_acc', #Metric to be measured\r\n",
    "                       factor=.01, #Factor by which learning rate will be reduced\r\n",
    "                       patience=3,  #No. of epochs after which if there is no improvement in the val_acc, the learning rate is reduced\r\n",
    "                       min_lr=1e-5) #The minimum learning rate \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\r\n",
    "\r\n",
    "'For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\r\n",
    "base_model_2 = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1= Sequential()\n",
    "model_1.add(base_model_1) #Adds the base model (in this case vgg19 to model_1)\n",
    "model_1.add(Flatten()) #Since the output before the flatten layer is a matrix we have to use this function to get a vector of the form nX1 to feed it into the fully connected layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "model_1.add(Dense(512,activation=('relu'))) \n",
    "model_1.add(Dense(256,activation=('relu'))) \n",
    "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
    "model_1.add(Dense(128,activation=('relu')))\n",
    "#model_1.add(Dropout(.2))\n",
    "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Check final model summary\n",
    "model_1.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size= 100\n",
    "epochs=50\n",
    "learn_rate=.001\n",
    "\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n",
    "                      epochs=epochs,\n",
    "                      steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n",
    "                      callbacks=[lrr],verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}